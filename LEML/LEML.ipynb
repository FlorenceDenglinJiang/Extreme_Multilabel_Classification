{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LEML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6gR24CTzDZw",
        "colab_type": "code",
        "outputId": "41ff84ec-a535-49ed-8ba1-b4fbe3d1fa7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1aHdNDmzJqQ",
        "colab_type": "code",
        "outputId": "276e55a9-84b2-4fbd-cbfe-7c568388a3d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/1003\\ Machine Learning/1003\\ Project/Data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1cXJSX-Wb546Od-de-PxfpA-IOtl_oV-Q/1003 Project/Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1eDmLbkL7lR",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "\n",
        "Code in this part credit to Man Jin: mj1637@nyu.edu\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssVS0uM7L7Pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8qeGsGZXCYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(file_name):\n",
        "\n",
        "    # load data from csv\n",
        "    data = pd.read_csv(file_name, usecols=['labels', 'features'])\n",
        "\n",
        "    # remove rows without proper label\n",
        "    rows_to_remove = [i for i in range(len(data)) if ':' in data.loc[i,'labels']]\n",
        "    data.drop(rows_to_remove, inplace=True)\n",
        "    data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # extract features from sparse representation\n",
        "    feature = np.zeros((len(data), 5000))\n",
        "    for i in range(len(data)):\n",
        "        for j in data.loc[i,'features'].replace('\\n','').split():\n",
        "            ft, val = j.split(':')\n",
        "            feature[i,int(ft)] = float(val)\n",
        "    X = pd.DataFrame(feature)\n",
        "\n",
        "    # extract labels\n",
        "    y = data['labels'].map(lambda x: tuple([int(i) for i in x.replace(' ','').split(',')]))\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcfudgu5L5FN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = load_data(\"train.csv\")\n",
        "X_val, y_val = load_data('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H01gqAmbUkUv",
        "colab_type": "code",
        "outputId": "cb3553b8-a829-424b-edc2-4b3cbef0b71f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Let's examine multi-labelness.\n",
        "m,n = X_train.shape\n",
        "q = max([label for y_i in y_train for label in y_i ])\n",
        "lCard = sum([len(y_train[i]) for i in range(m)])/m\n",
        "lDen = lCard/q\n",
        "\n",
        "print(\"m,n=\", (m,n))\n",
        "print(\"q=|y|=\", q)\n",
        "print(\"label diversity:\", len(np.unique(y_train)))\n",
        "print(\"label cardinality:\", lCard)\n",
        "print(\"label density:\", lDen)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m,n= (15511, 5000)\n",
            "q=|y|= 3992\n",
            "label diversity: 13543\n",
            "label cardinality: 5.320740119914899\n",
            "label density: 0.001332850731441608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udnXKnnQnt2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # if needed\n",
        "binarizer = MultiLabelBinarizer(classes=np.arange(3993))\n",
        "binary_y_train = binarizer.fit_transform(y_train)\n",
        "binary_y_val = binarizer.fit_transform(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS0Z-78HmXb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_small, binary_y_train_small = X_train[:1000], binary_y_train[:1000]\n",
        "X_val_small, binary_y_val_small = X_val[:250], binary_y_val[:250]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGpFHpoGsHYh",
        "colab_type": "text"
      },
      "source": [
        "# LEML\n",
        "\n",
        "http://proceedings.mlr.press/v32/yu14.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tbVSRdSsR_W",
        "colab_type": "code",
        "outputId": "a2ab6596-2043-488c-8034-8fb47d917271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# !git clone https://github.com/AnthonyMRios/leml.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'leml'...\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Total 149 (delta 0), reused 0 (delta 0), pack-reused 149\u001b[K\n",
            "Receiving objects: 100% (149/149), 1.64 MiB | 1.71 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j524RXvMsVOF",
        "colab_type": "code",
        "outputId": "777769f9-c4a9-4be1-efeb-6488d34ab2ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd leml/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1cXJSX-Wb546Od-de-PxfpA-IOtl_oV-Q/1003 Project/Data/leml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UGnmXEDshpH",
        "colab_type": "code",
        "outputId": "341cde26-bbf3-429b-8073-c485da910897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python2.7 setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing leml.egg-info/PKG-INFO\n",
            "writing top-level names to leml.egg-info/top_level.txt\n",
            "writing dependency_links to leml.egg-info/dependency_links.txt\n",
            "writing manifest file 'leml.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/lib.linux-x86_64-2.7\n",
            "creating build/lib.linux-x86_64-2.7/pyleml\n",
            "copying pyleml/LEML.py -> build/lib.linux-x86_64-2.7/pyleml\n",
            "copying pyleml/LEML_parallel.py -> build/lib.linux-x86_64-2.7/pyleml\n",
            "copying pyleml/LEML_single.py -> build/lib.linux-x86_64-2.7/pyleml\n",
            "copying pyleml/__init__.py -> build/lib.linux-x86_64-2.7/pyleml\n",
            "running build_ext\n",
            "skipping './pyleml/mul_sparse.c' Cython extension (up-to-date)\n",
            "building 'mul_sparse' extension\n",
            "creating build/temp.linux-x86_64-2.7\n",
            "creating build/temp.linux-x86_64-2.7/pyleml\n",
            "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-UKCoZ3/python2.7-2.7.17=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I/usr/include/python2.7 -c ./pyleml/mul_sparse.c -o build/temp.linux-x86_64-2.7/./pyleml/mul_sparse.o -fopenmp -O3 -ffast-math\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1822:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./pyleml/mul_sparse.c:435\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-UKCoZ3/python2.7-2.7.17=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I/usr/include/python2.7 -c ./pyleml/cs_gaxpy.c -o build/temp.linux-x86_64-2.7/./pyleml/cs_gaxpy.o -fopenmp -O3 -ffast-math\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-UKCoZ3/python2.7-2.7.17=. -fstack-protector-strong -Wformat -Werror=format-security -Wl,-Bsymbolic-functions -Wl,-z,relro -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-UKCoZ3/python2.7-2.7.17=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC build/temp.linux-x86_64-2.7/./pyleml/mul_sparse.o build/temp.linux-x86_64-2.7/./pyleml/cs_gaxpy.o -o build/lib.linux-x86_64-2.7/mul_sparse.so -fopenmp\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/pyleml\n",
            "copying build/lib.linux-x86_64-2.7/pyleml/LEML.py -> build/bdist.linux-x86_64/egg/pyleml\n",
            "copying build/lib.linux-x86_64-2.7/pyleml/LEML_parallel.py -> build/bdist.linux-x86_64/egg/pyleml\n",
            "copying build/lib.linux-x86_64-2.7/pyleml/LEML_single.py -> build/bdist.linux-x86_64/egg/pyleml\n",
            "copying build/lib.linux-x86_64-2.7/pyleml/__init__.py -> build/bdist.linux-x86_64/egg/pyleml\n",
            "copying build/lib.linux-x86_64-2.7/mul_sparse.so -> build/bdist.linux-x86_64/egg\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pyleml/LEML.py to LEML.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pyleml/LEML_parallel.py to LEML_parallel.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pyleml/LEML_single.py to LEML_single.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pyleml/__init__.py to __init__.pyc\n",
            "creating stub loader for mul_sparse.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mul_sparse.py to mul_sparse.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying leml.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying leml.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying leml.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying leml.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying leml.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "creating 'dist/leml-0.1-py2.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing leml-0.1-py2.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python2.7/dist-packages/leml-0.1-py2.7-linux-x86_64.egg\n",
            "Extracting leml-0.1-py2.7-linux-x86_64.egg to /usr/local/lib/python2.7/dist-packages\n",
            "Adding leml 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python2.7/dist-packages/leml-0.1-py2.7-linux-x86_64.egg\n",
            "Processing dependencies for leml==0.1\n",
            "Finished processing dependencies for leml==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzBL_1CEsjxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "# from pyleml import LEML"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze54Oe8htfXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as scipy_sp\n",
        "\n",
        "class LEMLs:\n",
        "    def __init__(self, num_factors = 128, num_iterations = 25, reg_param = 1.,\n",
        "                 stopping_criteria = 1e-3, cg_max_iter = 25, cg_gtol = 1e-3, verbose = False):\n",
        "        self.num_factors = num_factors\n",
        "        self.num_iterations = num_iterations\n",
        "        self.reg_param = reg_param\n",
        "        self.cg_max_iter = cg_max_iter\n",
        "        self.cg_gtol = cg_gtol\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def fit(self, train_data, train_labels):\n",
        "        self.W = np.random.random((train_data.shape[1], self.num_factors))\n",
        "        self.H = np.random.random((train_labels.shape[1], self.num_factors))\n",
        "\n",
        "        prev_loss = None\n",
        "        for iteration in range(self.num_iterations):\n",
        "            self.fit_H(train_data, train_labels)\n",
        "            num_cg_iters = self.fit_W(train_data, train_labels)\n",
        "            if self.verbose:\n",
        "                print('Iteration {} done'.format(iteration+1))\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        return test_data.dot(self.W).dot(self.H.T)>0.5\n",
        "    \n",
        "    def predict_proba(self, test_data):\n",
        "        return test_data.dot(self.W).dot(self.H.T)\n",
        "\n",
        "    def fit_H(self, train_data, train_labels):\n",
        "        X = train_data.dot(self.W)\n",
        "        X2 = X.T.dot(X)\n",
        "        eye_reg_param = np.eye(X2.shape[0])*self.reg_param\n",
        "        X2 = X2 + eye_reg_param\n",
        "        inv = np.linalg.inv(X2)\n",
        "        missing = train_labels.T.dot(X)\n",
        "        for j in range(train_labels.shape[1]):\n",
        "            self.H[j,:] =  inv.dot(missing[j,:].flatten()).flatten()\n",
        "\n",
        "    def fit_W(self, train_data, train_labels):\n",
        "        def vec(A):\n",
        "            return A.flatten('F')\n",
        "\n",
        "        def dloss(w, X, Y, H, reg_param):\n",
        "            W = self.W\n",
        "            A = X.dot(W)\n",
        "            B = Y.dot(H)\n",
        "            M = H.T.dot(H)\n",
        "            return vec(X.T.dot(A.dot(M)-B)) + reg_param*w\n",
        "\n",
        "        self.M = np.dot(self.H.T, self.H)\n",
        "        def Hs(s, X, reg_param):\n",
        "            S = s.reshape((X.shape[1],self.H.shape[1]), order='F')\n",
        "            A = X.dot(S)\n",
        "            AdM = A.dot(self.M)\n",
        "            XdAdM = X.T.dot(AdM)\n",
        "            v = vec(XdAdM)\n",
        "            return v + reg_param*s\n",
        "            #return vec((X.T.dot(A.dot(self.M)))) + reg_param*s\n",
        "\n",
        "        wt = vec(self.W)\n",
        "        rt = -dloss(wt, train_data, train_labels, self.H, self.reg_param)\n",
        "        dt = rt\n",
        "        total_iters = 0\n",
        "        for i in range(self.cg_max_iter):\n",
        "            if np.linalg.norm(rt) < self.cg_gtol:\n",
        "                break\n",
        "            total_iters += 1\n",
        "            hst = Hs(dt, train_data, self.reg_param)\n",
        "            rtdot = rt.T.dot(rt)\n",
        "            at = rtdot/(dt.T.dot(hst))\n",
        "            wt = wt + at*dt\n",
        "            rtp1 = rt - at*hst\n",
        "            bt = rtp1.T.dot(rtp1)/(rtdot)\n",
        "            rt = rtp1\n",
        "            dt = rt + bt*dt\n",
        "\n",
        "        self.W = wt.reshape((self.W.shape[0], self.W.shape[1]), order='F')\n",
        "\n",
        "        return total_iters\n",
        "\n",
        "\n",
        "\n",
        "import sys\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.metrics import precision_score \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# from pyleml import LEML\n",
        "\n",
        "# def main():\n",
        "#     print('Loading data')\n",
        "#     sys.stdout.flush()\n",
        "#     X = joblib.load('../example/test_data/bibtex-train.pkl')\n",
        "#     labels = joblib.load('../example/test_data/bibtex-Y-train.pkl')\n",
        "#     X_test = joblib.load('../example/test_data/bibtex-test.pkl')\n",
        "#     labels_test = joblib.load('../example/test_data/bibtex-Y-test.pkl')\n",
        "#     print(X.shape, labels.shape, X.getformat(), labels.getformat())\n",
        "\n",
        "#     print('Training LEML')\n",
        "#     sys.stdout.flush()\n",
        "#     #for l in [1e-3, 1e-2, 1e-1, 1., 10]:\n",
        "#     t0 = time()\n",
        "#     #leml = LEML.get_instance('single', num_factors=200, num_iterations=25, reg_param=1., verbose=True)\n",
        "#     leml = LEMLs(num_factors=200, num_iterations=5, reg_param=1., verbose=True)\n",
        "#     leml.fit(X.tocsr(), labels.tocsr())\n",
        "#     print('Train time', time() - t0, 'seconds')\n",
        "#     sys.stdout.flush()\n",
        "#     preds = leml.predict_proba(X_test)\n",
        "#     preds_top_k = preds.argsort()[:,::-1]\n",
        "#     preds_top_k = preds_top_k[:,:1]\n",
        "#     new_preds = np.zeros((preds.shape[0], preds.shape[1]))\n",
        "#     new_preds[np.arange(preds.shape[0]).repeat(1),preds_top_k.flatten()] = 1\n",
        "#     print('Precision @ 1:', precision_score(labels_test.toarray(), new_preds, average='samples'))\n",
        "\n",
        "#     preds_top_k = preds.argsort()[:,::-1]\n",
        "#     preds_top_k = preds_top_k[:,:3]\n",
        "#     new_preds = np.zeros((preds.shape[0], preds.shape[1]))\n",
        "#     new_preds[np.arange(preds.shape[0]).repeat(3),preds_top_k.flatten()] = 1\n",
        "#     print('Precision @ 3:', precision_score(labels_test.toarray(), new_preds, average='samples'))\n",
        "\n",
        "#     preds_top_k = preds.argsort()[:,::-1]\n",
        "#     preds_top_k = preds_top_k[:,:5]\n",
        "#     new_preds = np.zeros((preds.shape[0], preds.shape[1]))\n",
        "#     new_preds[np.arange(preds.shape[0]).repeat(5),preds_top_k.flatten()] = 1\n",
        "#     print('Precision @ 5:', precision_score(labels_test.toarray(), new_preds, average='samples'))\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvFixOuuywk4",
        "colab_type": "code",
        "outputId": "3172ece3-ff51-43f8-f5db-601ac4028b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(X_train_small), type(binary_y_train_small)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pandas.core.frame.DataFrame, numpy.ndarray)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6YDueglTpia",
        "colab_type": "text"
      },
      "source": [
        "## NUM_FACTORS = 500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAm_-eQAwNqu",
        "colab_type": "code",
        "outputId": "84007014-6f4b-4cfa-b744-a1d5b6763ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "leml = LEMLs(num_factors=500, num_iterations=20, reg_param=0.1, verbose=True)\n",
        "leml.fit(train_data = X_train_small.values, train_labels = binary_y_train_small)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 done\n",
            "Iteration 2 done\n",
            "Iteration 3 done\n",
            "Iteration 4 done\n",
            "Iteration 5 done\n",
            "Iteration 6 done\n",
            "Iteration 7 done\n",
            "Iteration 8 done\n",
            "Iteration 9 done\n",
            "Iteration 10 done\n",
            "Iteration 11 done\n",
            "Iteration 12 done\n",
            "Iteration 13 done\n",
            "Iteration 14 done\n",
            "Iteration 15 done\n",
            "Iteration 16 done\n",
            "Iteration 17 done\n",
            "Iteration 18 done\n",
            "Iteration 19 done\n",
            "Iteration 20 done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq2_XL0vw7pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = leml.predict(X_val_small)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9mlVl7_zhP5",
        "colab_type": "code",
        "outputId": "499912b3-78a3-41bb-dfb8-3ac35977fbf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate lrap\n",
        "import numpy as np\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "\n",
        "label_ranking_average_precision_score(binary_y_val_small, np.multiply(predictions.values, 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10429081661901443"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4fBIXj4TsOl",
        "colab_type": "text"
      },
      "source": [
        "## NUM_FACTORS = 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZGZjbqvTttB",
        "colab_type": "code",
        "outputId": "c6eaf232-cc85-4555-dba4-5dd877054481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "leml = LEMLs(num_factors=1000, num_iterations=20, reg_param=0.1, verbose=True)\n",
        "leml.fit(train_data = X_train_small.values, train_labels = binary_y_train_small)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 done\n",
            "Iteration 2 done\n",
            "Iteration 3 done\n",
            "Iteration 4 done\n",
            "Iteration 5 done\n",
            "Iteration 6 done\n",
            "Iteration 7 done\n",
            "Iteration 8 done\n",
            "Iteration 9 done\n",
            "Iteration 10 done\n",
            "Iteration 11 done\n",
            "Iteration 12 done\n",
            "Iteration 13 done\n",
            "Iteration 14 done\n",
            "Iteration 15 done\n",
            "Iteration 16 done\n",
            "Iteration 17 done\n",
            "Iteration 18 done\n",
            "Iteration 19 done\n",
            "Iteration 20 done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2rkZIjloT1TK",
        "colab": {}
      },
      "source": [
        "predictions = leml.predict(X_val_small)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ab418413-be8e-4d59-c542-bc48a306f041",
        "id": "mgA5XDtyT1TS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate lrap\n",
        "import numpy as np\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "\n",
        "label_ranking_average_precision_score(binary_y_val_small, np.multiply(predictions.values, 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05863427773243243"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZH17JmjUECW",
        "colab_type": "text"
      },
      "source": [
        "## NUM_FACTORS = 5000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "06bc3108-ac85-4d81-86f8-8f38e3c1574b",
        "id": "LyKO1_efUOI1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "leml = LEMLs(num_factors=5000, num_iterations=20, reg_param=0.1, verbose=True)\n",
        "leml.fit(train_data = X_train_small.values, train_labels = binary_y_train_small)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 done\n",
            "Iteration 2 done\n",
            "Iteration 3 done\n",
            "Iteration 4 done\n",
            "Iteration 5 done\n",
            "Iteration 6 done\n",
            "Iteration 7 done\n",
            "Iteration 8 done\n",
            "Iteration 9 done\n",
            "Iteration 10 done\n",
            "Iteration 11 done\n",
            "Iteration 12 done\n",
            "Iteration 13 done\n",
            "Iteration 14 done\n",
            "Iteration 15 done\n",
            "Iteration 16 done\n",
            "Iteration 17 done\n",
            "Iteration 18 done\n",
            "Iteration 19 done\n",
            "Iteration 20 done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gGCtTYpaUOI8",
        "colab": {}
      },
      "source": [
        "predictions = leml.predict(X_val_small)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3b0c36af-6bf3-4f1a-8d93-6d11216c7f6d",
        "id": "TrEoPHGUUOI_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate lrap\n",
        "import numpy as np\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "\n",
        "label_ranking_average_precision_score(binary_y_val_small, np.multiply(predictions.values, 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10182233545337331"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}